{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\44787\\\\Desktop\\\\projects\\\\Potato-disease-end-to-end\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\44787\\\\Desktop\\\\projects\\\\Potato-disease-end-to-end'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelTrainingConfig:\n",
    "    root_dir: Path\n",
    "    dataset_path: Path\n",
    "    model_save: Path\n",
    "    BATCH_SIZE: int\n",
    "    IMAGE_SIZE: int\n",
    "    CHANNELS: int\n",
    "    EPOCHS: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.constants import PARAMS_PATH, CONFIG_PATH\n",
    "from src.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config=CONFIG_PATH,\n",
    "                 params=PARAMS_PATH) -> None:\n",
    "        self.config = read_yaml(config)\n",
    "        self.params = read_yaml(params)\n",
    "\n",
    "    def get_model_training_config(self) -> ModelTrainingConfig:\n",
    "        config = self.config.model_training\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_training_config = ModelTrainingConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            dataset_path=config.dataset_path,\n",
    "            model_save=config.model_save,\n",
    "            BATCH_SIZE=self.params.BATCH_SIZE,\n",
    "            IMAGE_SIZE=self.params.IMAGE_SIZE,\n",
    "            CHANNELS=self.params.CHANNELS,\n",
    "            EPOCHS=self.params.EPOCHS,\n",
    "        )\n",
    "        return model_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-23 21:38:39,148: WARNING: module_wrapper: From c:\\Users\\44787\\anaconda3\\envs\\potato-env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from src.logging import logger\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"]=\"https://dagshub.com/fraidoon_omarzai/Potato-disease-end-to-end.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]=\"fraidoon_omarzai\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=\"bc25b16bd5206328d8899cf34377f26ad71d1420\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTraining:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def split_dataset(self,\n",
    "                      dataset,\n",
    "                      train_split=0.8,\n",
    "                      test_split=0.1,\n",
    "                      val_split=0.1,\n",
    "                      shuffle=True):\n",
    "\n",
    "        assert (train_split+test_split+val_split) == 1\n",
    "\n",
    "        dataset_size = len(dataset)\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(10000, seed=42)\n",
    "\n",
    "        train_size = int(train_split * dataset_size)\n",
    "        val_size = int(val_split * dataset_size)\n",
    "\n",
    "        train_data = dataset.take(train_size)\n",
    "        val_data = dataset.skip(train_size).take(val_size)\n",
    "        test_data = dataset.skip(train_size).skip(val_size)\n",
    "\n",
    "        return train_data, val_data, test_data\n",
    "\n",
    "    def prepare_dataset(self):\n",
    "        dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            self.config.dataset_path,\n",
    "            image_size=(self.config.IMAGE_SIZE, self.config.IMAGE_SIZE),\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            shuffle=True\n",
    "        )\n",
    "        logger.info(f'name of classes: {dataset.class_names}')\n",
    "\n",
    "        train_data, val_data, test_data = self.split_dataset(dataset)\n",
    "\n",
    "        train_data = train_data.cache().shuffle(\n",
    "            1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        val_data = val_data.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        test_data = test_data.cache().shuffle(\n",
    "            1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "        # applay data agumentation to train dataset\n",
    "        data_augmentation = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.RandomFlip(\n",
    "                \"horizontal_and_vertical\"),\n",
    "            tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        ])\n",
    "        train_data = train_data.map(lambda x, y:\n",
    "                                    (data_augmentation(x, training=True), y)).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "        return train_data, val_data, test_data\n",
    "\n",
    "    def training(self):\n",
    "        resize_and_rescale = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.Resizing(\n",
    "                self.config.IMAGE_SIZE, self.config.IMAGE_SIZE),\n",
    "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "        ])\n",
    "\n",
    "        # create a model architecture\n",
    "        input_shape = (self.config.BATCH_SIZE, self.config.IMAGE_SIZE,\n",
    "                       self.config.IMAGE_SIZE, self.config.CHANNELS)\n",
    "        n_classes = 3\n",
    "\n",
    "        \n",
    "        model = tf.keras.models.Sequential([\n",
    "            resize_and_rescale,\n",
    "            tf.keras.layers.Conv2D(32, kernel_size=(\n",
    "                3, 3), activation='relu', input_shape=input_shape),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64,  kernel_size=(3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64,  kernel_size=(3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "            tf.keras.layers.Dense(n_classes, activation='softmax'),\n",
    "        ])\n",
    "        model.build(input_shape=input_shape)\n",
    "        logger.info(model.summary())\n",
    "\n",
    "        # compile the model\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                from_logits=False),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        train_data, val_data, test_data = self.prepare_dataset()\n",
    "\n",
    "        mlflow.set_experiment('Tensorflow Models')\n",
    "        mlflow.set_registry_uri('https://dagshub.com/fraidoon_omarzai/Potato-disease-end-to-end.mlflow')\n",
    "        \n",
    "        with mlflow.start_run(run_name=\"Tf\") as mlops_run:\n",
    "        \n",
    "            # train the model\n",
    "            model.fit(\n",
    "                train_data,\n",
    "                batch_size=self.config.BATCH_SIZE,\n",
    "                validation_data=val_data,\n",
    "                verbose=1,\n",
    "                epochs=self.config.EPOCHS\n",
    "            )\n",
    "            \n",
    "            # evaluate the model\n",
    "            results = model.evaluate(test_data)\n",
    "            logger.info(f\"Model evaluation: {results}\")\n",
    "            \n",
    "            mlflow.log_param('batch size', self.config.BATCH_SIZE)\n",
    "            mlflow.log_param('epochs', self.config.EPOCHS)\n",
    "            \n",
    "            mlflow.log_metric('accuracy', results[1])\n",
    "            \n",
    "            tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "            if tracking_url_type_store != \"file\":\n",
    "\n",
    "                # Register the model\n",
    "                # There are other ways to use the Model Registry, which depends on the use case,\n",
    "                # please refer to the doc for more information:\n",
    "                # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "                mlflow.tensorflow.log_model(model, \"model\", registered_model_name=\"TFModel\")\n",
    "            else:\n",
    "                mlflow.tensorflow.log_model(model, \"model\")\n",
    "        \n",
    "\n",
    "    #     self.save_model(\n",
    "    #         self.config.model_save,\n",
    "    #         model\n",
    "    #     )\n",
    "\n",
    "    # @staticmethod\n",
    "    # def save_model(path: Path, model: tf.keras.Model):\n",
    "    #     model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-18 10:56:34,367: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-12-18 10:56:34,374: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-18 10:56:34,377: INFO: common: created directory at: artifacts/model_training]\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_3 (Sequential)   (32, 256, 256, 3)         0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (32, 254, 254, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (32, 127, 127, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (32, 125, 125, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (32, 62, 62, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (32, 60, 60, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (32, 30, 30, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (32, 28, 28, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (32, 14, 14, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (32, 12, 12, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (32, 6, 6, 64)            0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (32, 4, 4, 64)            36928     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (32, 2, 2, 64)            0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (32, 256)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (32, 64)                  16448     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (32, 3)                   195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183747 (717.76 KB)\n",
      "Trainable params: 183747 (717.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "[2023-12-18 10:56:34,637: INFO: 2247739627: None]\n",
      "Found 2152 files belonging to 3 classes.\n",
      "[2023-12-18 10:56:35,104: INFO: 2247739627: name of classes: ['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/18 10:56:35 INFO mlflow.tracking.fluent: Experiment with name 'Tensorflow Models' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "54/54 [==============================] - 35s 564ms/step - loss: 0.9138 - accuracy: 0.4953 - val_loss: 0.8136 - val_accuracy: 0.6198\n",
      "Epoch 2/2\n",
      "54/54 [==============================] - 26s 476ms/step - loss: 0.6772 - accuracy: 0.7160 - val_loss: 0.7819 - val_accuracy: 0.5885\n",
      "8/8 [==============================] - 2s 126ms/step - loss: 0.8310 - accuracy: 0.5781\n",
      "[2023-12-18 10:57:40,106: INFO: 2247739627: Model evaluation: [0.8309705257415771, 0.578125]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/18 10:57:40 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-18 10:57:42,917: INFO: builder_impl: Assets written to: C:\\Users\\44787\\AppData\\Local\\Temp\\tmp7tkx6mf0\\model\\data\\model\\assets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'TFModel' already exists. Creating a new version of this model...\n",
      "2023/12/18 10:58:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: TFModel, version 2\n",
      "Created version '2' of model 'TFModel'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_training_config = config.get_model_training_config()\n",
    "    model_training = ModelTraining(model_training_config)\n",
    "    model_training.training()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "potato-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
